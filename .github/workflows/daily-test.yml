name: Daily E2E Test

on:
  schedule:
    # æ¯æ—¥å‡Œæ™¨ 2 ç‚¹ (UTC) è¿è¡Œï¼ŒåŒ—äº¬æ—¶é—´ 10:00
    - cron: '0 2 * * *'

  # æ”¯æŒæ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      test_scope:
        description: 'æµ‹è¯•èŒƒå›´'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - e2e
          - integration
          - unit

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          playwright install chromium --with-deps

      - name: Create necessary directories
        run: |
          mkdir -p data screenshots reports

      - name: Discover products
        run: |
          python scripts/discover_products.py --max-products 50
        continue-on-error: true

      - name: Run tests
        id: tests
        run: |
          SCOPE="${{ github.event.inputs.test_scope || 'all' }}"

          if [ "$SCOPE" = "all" ]; then
            pytest tests/ -v -n 4 \
              --html=reports/test-report.html \
              --self-contained-html \
              --maxfail=10
          elif [ "$SCOPE" = "e2e" ]; then
            pytest tests/e2e/ -v -n 2 \
              --html=reports/e2e-report.html \
              --self-contained-html
          elif [ "$SCOPE" = "integration" ]; then
            pytest tests/integration/ -v \
              --html=reports/integration-report.html \
              --self-contained-html
          else
            pytest tests/unit/ -v \
              --html=reports/unit-report.html \
              --self-contained-html
          fi
        continue-on-error: true

      - name: Collect test results
        if: always()
        run: |
          python scripts/collect_test_results.py \
            --output reports/test-results.json

      - name: Generate AI report
        if: always()
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          python scripts/generate_universal_ai_report.py \
            --provider deepseek \
            --output reports/ai-report.md
        continue-on-error: true

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-${{ github.run_number }}
          path: |
            reports/
            screenshots/
          retention-days: 30

      - name: Upload test results summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_number }}
          path: reports/test-results.json
          retention-days: 90

      - name: Check test results and alert
        if: failure()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -f "scripts/send_alerts.py" ]; then
            python scripts/send_alerts.py \
              --channel slack \
              --results-file reports/test-results.json
          else
            echo "âš ï¸ Alert script not found, skipping alerts"
          fi
        continue-on-error: true

      - name: Comment on commit (if failed)
        if: failure() && github.event_name == 'push'
        uses: peter-evans/commit-comment@v3
        with:
          body: |
            ğŸš¨ **Daily E2E Test Failed**

            æµ‹è¯•è¿è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šã€‚

            - è¿è¡Œç¼–å·: ${{ github.run_number }}
            - è§¦å‘æ–¹å¼: ${{ github.event_name }}
            - æŸ¥çœ‹æŠ¥å‘Š: [Test Reports](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

      - name: Create issue on repeated failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•ç»“æœæ–‡ä»¶
            if (!fs.existsSync('reports/test-results.json')) {
              console.log('No test results found');
              return;
            }

            const results = JSON.parse(fs.readFileSync('reports/test-results.json', 'utf8'));

            // ä»…åœ¨é€šè¿‡ç‡ä½äº 80% æ—¶åˆ›å»º Issue
            if (results.pass_rate < 0.8) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `ğŸš¨ Daily Test Failed - Pass Rate: ${(results.pass_rate * 100).toFixed(1)}%`,
                body: `## æµ‹è¯•å¤±è´¥æŠ¥å‘Š

                **è¿è¡Œç¼–å·**: ${{ github.run_number }}
                **è§¦å‘æ—¶é—´**: ${new Date().toISOString()}
                **é€šè¿‡ç‡**: ${(results.pass_rate * 100).toFixed(1)}%

                ### ç»Ÿè®¡ä¿¡æ¯
                - æ€»æµ‹è¯•æ•°: ${results.total}
                - é€šè¿‡: ${results.passed}
                - å¤±è´¥: ${results.failed}
                - è·³è¿‡: ${results.skipped}

                ### æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š
                [æµ‹è¯•æŠ¥å‘Š](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

                è¯·å°½å¿«æŸ¥çœ‹å¹¶ä¿®å¤å¤±è´¥çš„æµ‹è¯•ã€‚`,
                labels: ['bug', 'test-failure', 'automated']
              });
            }
